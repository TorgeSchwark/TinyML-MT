{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge dataset to our dataset format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"rewe-roboflow\" # CHANGE\n",
    "dataset_path = \"datasets/rewe-roboflow/train\" # CHANGE\n",
    "dataset_labels = \"datasets/rewe-roboflow/data.yaml\" # CHANGE\n",
    "\n",
    "# Source Dataset Paths\n",
    "id_path = \"Dataset/id.txt\"\n",
    "prices_path = \"Dataset/prices.txt\"\n",
    "destination = \"Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price & label preparation\n",
    "\n",
    "Find the current image and label id count to label the new images and classes correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id count:  2841\n",
      "Label count:  7\n"
     ]
    }
   ],
   "source": [
    "with open(id_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    id_count = int(lines[0].split()[1]) + 1\n",
    "    label_count = int(lines[1].split()[1]) + 1\n",
    "\n",
    "print(\"Id count: \", id_count)\n",
    "print(\"Label count: \", label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ActiveO2_Orange_Bio', 'AlpensalzJodFluor', 'Barilla_Collezione', 'Burste', 'ChristiansGrod-Rotegruetze-sauerkirsch', 'CupNoodlesSobaWok', 'DallmayrProdomo-naturmild', 'DrOetketZitronenWolke', 'Eissbergsalat', 'HarryVitalFit', 'Heinz_Curry_mango', 'Heinz_tomato', 'Hitchcock-Zitrone', 'Ja-DinkelSpaghetti', 'Kinder_Riegel_Big', 'Kuehne_RoteBeete', 'Kuehne_Schlemmer_Topfchen_Balsamico', 'Lenor_Waschmittel', 'Maggi-PutenWok', 'Mesmer-HimbeerLemon', 'NicNacsDouble', 'Pedigree_Markies_Original', 'PringlesHotSpicy', 'ReweBW_Besto_Balsamico', 'ShebaSauceSpeciale', 'Speisekartoffeln_Regional', 'SweetKiss', 'hella_wellness', 'ja-Gouda', 'ja-H-Milch-0', 'ja-Salami', 'ja-_Kiechererbsen']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Open the labels_path file and load its content\n",
    "with open(dataset_labels , 'r') as file:\n",
    "    labels_data = yaml.safe_load(file)\n",
    "\n",
    "# Extract the files under the 'name' key\n",
    "labels = labels_data.get('names', [])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the price and give the labels new labels if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added label and price: vitamine water 1.19\n",
      "Added label and price: salt  1.29\n",
      "Added label and price: barilla noodles 2.69\n",
      "Added label and price: brush 0.79\n",
      "Added label and price: red fruit jelly 2.29\n",
      "Added label and price: cup noodles  2.19\n",
      "Added label and price: coffee beans  7.99\n",
      "Added label and price: lemon cake baking mix  3.49\n",
      "Added label and price: lettuce 1.11\n",
      "Added label and price: bread 1.89\n",
      "Added label and price: curry sauce 2.29\n",
      "Added label and price: tomato ketchup 2.29\n",
      "Added label and price: lemon juice 1.59\n",
      "Added label and price: spaghetti 1.29\n",
      "Added label and price: kinder riegel 2.99\n",
      "Added label and price: beetroot 1.79\n",
      "Added label and price: pickles 3.49\n",
      "Added label and price: detergent 3.79\n",
      "Added label and price: maggi wok 1.05\n",
      "Added label and price: tea 2.35\n",
      "Added label and price: nic nacs 1.99\n",
      "Added label and price: pedigree dog food 2.29\n",
      "Added label and price: pringles 2.49\n",
      "Added label and price: balsamico 2.69\n",
      "Added label and price: cat food bowl 0.65\n",
      "Added label and price: potatoes 1.99\n",
      "Added label and price: red tea 2.49\n",
      "Added label and price: hella water 0.79\n",
      "Added label and price: gouda 2.19\n",
      "Added label and price: oat milk 0.99\n",
      "Added label and price: salami 1.79\n",
      "Added label and price: chickpeas 0.59\n",
      "{7: ['vitamine water', 1.19], 8: ['salt ', 1.29], 9: ['barilla noodles', 2.69], 10: ['brush', 0.79], 11: ['red fruit jelly', 2.29], 12: ['cup noodles ', 2.19], 13: ['coffee beans ', 7.99], 14: ['lemon cake baking mix ', 3.49], 15: ['lettuce', 1.11], 16: ['bread', 1.89], 17: ['curry sauce', 2.29], 18: ['tomato ketchup', 2.29], 19: ['lemon juice', 1.59], 20: ['spaghetti', 1.29], 21: ['kinder riegel', 2.99], 22: ['beetroot', 1.79], 23: ['pickles', 3.49], 24: ['detergent', 3.79], 25: ['maggi wok', 1.05], 26: ['tea', 2.35], 27: ['nic nacs', 1.99], 28: ['pedigree dog food', 2.29], 29: ['pringles', 2.49], 30: ['balsamico', 2.69], 31: ['cat food bowl', 0.65], 32: ['potatoes', 1.99], 33: ['red tea', 2.49], 34: ['hella water', 0.79], 35: ['gouda', 2.19], 36: ['oat milk', 0.99], 37: ['salami', 1.79], 38: ['chickpeas', 0.59]}\n"
     ]
    }
   ],
   "source": [
    "label_to_price = {}\n",
    "num_to_label = {}\n",
    "i = 0\n",
    "for label in labels:\n",
    "    new_label = input(f\"Enter the new label for {label} (Skip): \")\n",
    "    if new_label == \"\":\n",
    "        new_label = label\n",
    "    price = float(input(f\"Enter the price for {label}: \"))\n",
    "    label_to_price[label_count] = [new_label,price]\n",
    "    num_to_label[i] = label_count\n",
    "    label_count += 1\n",
    "    print(\"Added label and price:\", new_label, price)\n",
    "    i += 1\n",
    "\n",
    "print(label_to_price )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_yolo(source_folder, filename):\n",
    "    class_occurrences = {}\n",
    "    with open(os.path.join(source_folder+\"/labels\", filename), 'r') as file:\n",
    "        # Change this part if the labels are given differently then yolo\n",
    "        for line in file:\n",
    "            first_number = int(line.split()[0])\n",
    "            new_label = num_to_label[first_number]\n",
    "            if new_label not in class_occurrences:\n",
    "                class_occurrences[new_label] = 1\n",
    "            else:    \n",
    "                class_occurrences[new_label] += 1\n",
    "    return class_occurrences            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the files this assumes the images to be in images and labels in a labels folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mid\u001b[39m         \n\u001b[0;32m---> 34\u001b[0m id_count \u001b[38;5;241m=\u001b[39m process_and_save_files(\u001b[43mdataset_path\u001b[49m, destination\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdataset_name, id_count, label_to_price, num_to_label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_path' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def process_and_save_files(source_folder, destination_folder, start_id, label_to_price, num_to_label):\n",
    "    id = start_id\n",
    "    for filename in os.listdir(source_folder+\"/labels\"):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "            # Read the content of the txt file\n",
    "            class_occurrences = extract_yolo(source_folder, filename)\n",
    "            \n",
    "            # Save the new txt file in the destination folder with a new name\n",
    "            new_filename = f\"image_{id}.txt\"\n",
    "            overall_price = 0\n",
    "            for key in class_occurrences:\n",
    "                overall_price += label_to_price[key][1] * class_occurrences[key]\n",
    "\n",
    "            with open(os.path.join(destination_folder, new_filename), 'w') as new_file:\n",
    "                new_file.write(\"Objects: \"+ str(class_occurrences)+ \"\\nTotal Price: \"+ \"{:.2f}\".format(overall_price))\n",
    "            \n",
    "            # Assuming there is a corresponding jpg file with the same name\n",
    "            jpg_filename = filename.replace(\".txt\", \".jpg\")\n",
    "            if os.path.exists(os.path.join(source_folder+\"/images\", jpg_filename)):\n",
    "                # Open the image file\n",
    "                image = Image.open(os.path.join(source_folder+\"/images\", jpg_filename))\n",
    "                \n",
    "                # Save the new image in the destination folder with a new name\n",
    "                new_image_filename = f\"image_{id}.jpg\"\n",
    "                image.save(os.path.join(destination_folder, new_image_filename))\n",
    "            id += 1\n",
    "    return id         \n",
    "\n",
    "\n",
    "id_count = process_and_save_files(dataset_path, destination+\"/\"+dataset_name, id_count, label_to_price, num_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save new id and price dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(id_path, 'w') as f:\n",
    "    f.write(f\"image_id: {id_count-1}\\n\")\n",
    "    f.write(f\"label_id: {label_count-1}\")\n",
    "\n",
    "with open(prices_path, 'a+') as file:\n",
    "    # Move to the start of the file and read the content\n",
    "    file.seek(0)\n",
    "    content = file.read()\n",
    "\n",
    "    # If the file is not empty and does not end with a newline, add one\n",
    "    if content and not content.endswith('\\n'):\n",
    "        file.write('\\n')\n",
    "\n",
    "    # Write the new content on a new line\n",
    "    file.write(dataset_name + \": \" + str(label_to_price) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic price finding testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "def get_prices(labels):\n",
    "    new_label_price = {}\n",
    "    # Load the CSV file into a DataFrame\n",
    "    csv_path = \"schleswig-holstein-prices.csv\"\n",
    "    csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Assuming the CSV has columns 'Name' and 'Price'\n",
    "    csv_names = csv_data['name'].tolist()\n",
    "    csv_prices = csv_data['price'].tolist()\n",
    "\n",
    "    # Function to find the closest match and its price\n",
    "    def find_closest_price(label, csv_names, csv_prices):\n",
    "        closest_match = get_close_matches(label, csv_names, n=1, cutoff=0.0)\n",
    "        if closest_match:\n",
    "            index = csv_names.index(closest_match[0])\n",
    "            print(label, \"|\",closest_match[0], '|', csv_prices[index])\n",
    "            return csv_prices[index]\n",
    "        return None\n",
    "\n",
    "    # Update label_price with the closest prices from the CSV\n",
    "    for label in labels:\n",
    "        closest_price = find_closest_price(label, csv_names, csv_prices)\n",
    "        if closest_price is not None:\n",
    "            new_label_price[label] = closest_price\n",
    "\n",
    "    return new_label_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avocado | Avocado\n",
      "beans | Bohnen\n",
      "beet | Rüben\n",
      "bell pepper | Glockenpfeffer\n",
      "broccoli | Brokkoli\n",
      "brus capusta | brus capusta\n",
      "cabbage | Kohl\n",
      "carrot | Karotte\n",
      "cayliflower | cayliflower\n",
      "celery | Sellerie\n",
      "corn | Mais\n",
      "cucumber | Gurke\n",
      "eggplant | aubergine\n",
      "fasol | fasol\n",
      "garlic | Knoblauch\n",
      "hot pepper | Paprika\n",
      "onion | Zwiebel\n",
      "peas | Erbsen\n",
      "potato | Kartoffel\n",
      "pumpkin | Kürbis\n",
      "rediska | rediska\n",
      "redka | redka\n",
      "salad | Salat\n",
      "squash-patisson | squash-patisson\n",
      "tomato | Tomate\n",
      "vegetable marrow | Markkuerbis\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "vegetables = [\n",
    "    \"avocado\",\n",
    "    \"beans\",\n",
    "    \"beet\",\n",
    "    \"bell pepper\",\n",
    "    \"broccoli\",\n",
    "    \"brus capusta\",\n",
    "    \"cabbage\",\n",
    "    \"carrot\",\n",
    "    \"cayliflower\",\n",
    "    \"celery\",\n",
    "    \"corn\",\n",
    "    \"cucumber\",\n",
    "    \"eggplant\",\n",
    "    \"fasol\",\n",
    "    \"garlic\",\n",
    "    \"hot pepper\",\n",
    "    \"onion\",\n",
    "    \"peas\",\n",
    "    \"potato\",\n",
    "    \"pumpkin\",\n",
    "    \"rediska\",\n",
    "    \"redka\",\n",
    "    \"salad\",\n",
    "    \"squash-patisson\",\n",
    "    \"tomato\",\n",
    "    \"vegetable marrow\"\n",
    "]\n",
    "for veggie in vegetables:\n",
    "    translator = Translator(to_lang='de')\n",
    "    translation = translator.translate(veggie)\n",
    "    print(veggie, \"|\", translation)\n",
    "#get_prices(vegetables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest number in the txt files is: 2789\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_highest_number_in_txt_files(directory):\n",
    "    highest_number = None\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            number_str = filename.split('_')[-1].split('.')[0]\n",
    "            try:\n",
    "                number = int(number_str)\n",
    "                if highest_number is None or number > highest_number:\n",
    "                    highest_number = number\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return highest_number\n",
    "\n",
    "highest_number = find_highest_number_in_txt_files(dataset_destination_path)\n",
    "print(f\"The highest number in the txt files is: {highest_number}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
