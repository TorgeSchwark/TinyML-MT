{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4592e210",
   "metadata": {},
   "source": [
    "# Interacting with Huggingface (HF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006851e",
   "metadata": {},
   "source": [
    "### HF Limitations for our datasets\n",
    "To upload our datasets to HF for easy distribution we use a non-trivial approach as most of our datasets are very large and HF has limits\n",
    "- Not more than 10k files per folder\n",
    "- Not more than 100k in total\n",
    "- Loading with COCO format is not really supported\n",
    "  \n",
    "### Our approach\n",
    "Because of this we zip all image and label files in the respective folders when uploading and unzip them when downloading. Just follow this setup as it gides you through the process. \n",
    "\n",
    "Note: Normal Git usage with HF is not really supported as tracking doesnt work since we zip/unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb04874",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd61ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data22/stu236894/GitRepos/TinyML-MT/basket/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5d576",
   "metadata": {},
   "source": [
    "## Login to HF\n",
    "The cache is not directly used for our method but just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bcf8ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorgeSchwark\n",
      "\u001b[1morgs: \u001b[0m Basket-AEye\n"
     ]
    }
   ],
   "source": [
    "# HF Cache\n",
    "os.environ[\"HF_HOME\"] = \"../../.cache\"\n",
    "!echo $HF_HOME\n",
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a39e49",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f466b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"ai_shelf/sd/10classes\" # Starting from a local huggingface folder in the repo\n",
    "HF_REPO = \"Basket-AEye/ai_shelf10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c1e1f",
   "metadata": {},
   "source": [
    "# Upload to HF\n",
    "\n",
    "We only zip in subdirectories so any txt, json files in the first level are not zipped and can be used for HF settings and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1dcb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder zipped to ../../huggingface/ai_shelf/artificial_created_dataset/images/train.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.zip: 100%|██████████| 137M/137M [00:09<00:00, 15.0MB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /images/train.zip uploaded to Basket-AEye/first_artificial\n",
      "Folder zipped to ../../huggingface/ai_shelf/artificial_created_dataset/images/val.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val.zip: 100%|██████████| 41.1M/41.1M [00:01<00:00, 35.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /images/val.zip uploaded to Basket-AEye/first_artificial\n",
      "Folder zipped to ../../huggingface/ai_shelf/artificial_created_dataset/images/test.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test.zip: 100%|██████████| 13.4M/13.4M [00:00<00:00, 37.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /images/test.zip uploaded to Basket-AEye/first_artificial\n",
      "Folder zipped to ../../huggingface/ai_shelf/artificial_created_dataset/labels/train.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.zip: 100%|██████████| 195k/195k [00:00<00:00, 753kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /labels/train.zip uploaded to Basket-AEye/first_artificial\n",
      "Folder zipped to ../../huggingface/ai_shelf/artificial_created_dataset/labels/val.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val.zip: 100%|██████████| 58.6k/58.6k [00:00<00:00, 290kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /labels/val.zip uploaded to Basket-AEye/first_artificial\n",
      "Folder zipped to ../../huggingface/ai_shelf/artificial_created_dataset/labels/test.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test.zip: 100%|██████████| 18.8k/18.8k [00:00<00:00, 114kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /labels/test.zip uploaded to Basket-AEye/first_artificial\n"
     ]
    }
   ],
   "source": [
    "created_zips = []\n",
    "\n",
    "# ----- Functions -----\n",
    "def zip_folder(folder_path, output_zip):\n",
    "    \"\"\"Zips the contents of a folder.\"\"\"\n",
    "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, folder_path)\n",
    "                zipf.write(file_path, arcname)\n",
    "    print(f\"Folder zipped to {output_zip}\")\n",
    "    created_zips.append(output_zip)\n",
    "\n",
    "def upload_to_hf(path, repo_path):\n",
    "    \"\"\"Uploads a file to Hugging Face Hub.\"\"\"\n",
    "    api = HfApi()\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=path,\n",
    "        path_in_repo=repo_path,\n",
    "        repo_id=HF_REPO,\n",
    "        repo_type=\"dataset\"\n",
    "    )\n",
    "    print(f\"File {repo_path} uploaded to {HF_REPO}\")\n",
    "\n",
    "complete_dir = os.path.join(\"../../huggingface/\", DATASET_DIR)\n",
    "\n",
    "# Go through each folder in the dataset directory\n",
    "def process_folder(folder_path, repo_prefix):\n",
    "    \"\"\"Processes a folder, zipping and uploading its contents recursively.\"\"\"\n",
    "    contains_image_or_text = any(\n",
    "        file.endswith(('.png', '.jpg', '.jpeg', '.txt', '.json'))\n",
    "        for file in os.listdir(folder_path)\n",
    "    )\n",
    "    if contains_image_or_text:\n",
    "        zip_path = f\"{folder_path}.zip\"\n",
    "        zip_folder(folder_path, zip_path)\n",
    "        upload_to_hf(zip_path, repo_prefix + f\"/{os.path.basename(folder_path)}.zip\")\n",
    "    else:\n",
    "        for item in os.listdir(folder_path):\n",
    "            item_path = os.path.join(folder_path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                process_folder(item_path, repo_prefix + f\"/{os.path.basename(folder_path)}\")\n",
    "            elif os.path.isfile(item_path):\n",
    "                upload_to_hf(item_path, repo_prefix + f\"/{os.path.basename(folder_path)}/{item}\")\n",
    "\n",
    "# ----- Main -----\n",
    "if not os.path.exists(complete_dir):\n",
    "    print(f\"Directory {complete_dir} does not exist.\")\n",
    "    exit(1)\n",
    "\n",
    "# Get a list of all folders in the complete directory\n",
    "folder_paths = [os.path.join(complete_dir, item) for item in os.listdir(complete_dir) if os.path.isdir(os.path.join(complete_dir, item))]\n",
    "\n",
    "# Execute process_folder for each folder in the list\n",
    "for folder_path in folder_paths:\n",
    "    process_folder(folder_path, \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e3c8c",
   "metadata": {},
   "source": [
    "### Remove zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7892164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ../../huggingface/ai_shelf/artificial_created_dataset/images/train.zip\n",
      "Removed ../../huggingface/ai_shelf/artificial_created_dataset/images/val.zip\n",
      "Removed ../../huggingface/ai_shelf/artificial_created_dataset/images/test.zip\n",
      "Removed ../../huggingface/ai_shelf/artificial_created_dataset/labels/train.zip\n",
      "Removed ../../huggingface/ai_shelf/artificial_created_dataset/labels/val.zip\n",
      "Removed ../../huggingface/ai_shelf/artificial_created_dataset/labels/test.zip\n"
     ]
    }
   ],
   "source": [
    "for zip_file in created_zips:\n",
    "    if os.path.exists(zip_file):\n",
    "        os.remove(zip_file)\n",
    "        print(f\"Removed {zip_file}\")\n",
    "    else:\n",
    "        print(f\"{zip_file} does not exist.\")\n",
    "created_zips.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734844a0",
   "metadata": {},
   "source": [
    "# Download from HF\n",
    "\n",
    "This process removes the local directory, redownloads the entire repo and unzips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1af9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing directory: ../../huggingface/ai_shelf/sd/10classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded snapshot of repo Basket-AEye/ai_shelf10 to /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/coffee.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/coffee\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/apple.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/apple\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/banana.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/banana\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/oatmeal.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/oatmeal\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/lemon.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/lemon\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/pasta.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/pasta\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/fruit tea.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/fruit tea\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/tomato sauce.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/tomato sauce\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/avocado.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/avocado\n",
      "Unzipped /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/cucumber.zip into /data22/stu236894/GitRepos/TinyML-MT/huggingface/ai_shelf/sd/10classes/cucumber\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "complete_dir = os.path.join(\"../../huggingface/\", DATASET_DIR)\n",
    "\n",
    "# Check if the path exists and delete it\n",
    "if os.path.exists(complete_dir):\n",
    "    #shutil.rmtree(complete_dir)\n",
    "    print(f\"Existing directory: {complete_dir}\")\n",
    "\n",
    "# Download the repo from HF using snapshot_download\n",
    "snapshot_path = snapshot_download(\n",
    "    repo_id=HF_REPO,\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=complete_dir\n",
    ")\n",
    "print(f\"Downloaded snapshot of repo {HF_REPO} to {snapshot_path}\")\n",
    "# Unzip all zip files recursively and put files into a folder with the name of the zip\n",
    "for root, dirs, files in os.walk(snapshot_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            zip_path = os.path.join(root, file)\n",
    "            folder_name = os.path.splitext(file)[0]  # Get the name of the zip file without extension\n",
    "            extract_path = os.path.join(root, folder_name)  # Create a folder with the name of the zip\n",
    "            os.makedirs(extract_path, exist_ok=True)  # Ensure the folder exists\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_path)  # Extract files into the folder\n",
    "            # os.remove(zip_path)  # Uncomment for better caching but takes more space\n",
    "            print(f\"Unzipped {zip_path} into {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8990d9",
   "metadata": {},
   "source": [
    "## Remove zip files (No caching)\n",
    "When downloading we leave the zip files for caching: Comparing the two zip files and then not redownloading if same (TAKES MORE STORAGE THOUGH)\n",
    "If not wanted execute the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec4a893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ../../huggingface/ai_shelf/sd/10classes/coffee.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/apple.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/banana.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/oatmeal.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/lemon.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/pasta.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/fruit tea.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/tomato sauce.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/avocado.zip\n",
      "Removed ../../huggingface/ai_shelf/sd/10classes/cucumber.zip\n"
     ]
    }
   ],
   "source": [
    "complete_dir = os.path.join(\"../../huggingface/\", DATASET_DIR)\n",
    "\n",
    "for root, dirs, files in os.walk(complete_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            zip_path = os.path.join(root, file)\n",
    "            os.remove(zip_path)\n",
    "            print(f\"Removed {zip_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basket (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
