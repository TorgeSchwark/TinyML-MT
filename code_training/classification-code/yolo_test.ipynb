{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f7759347",
            "metadata": {},
            "source": [
                "# YOLO Training & Testing"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4f799271",
            "metadata": {},
            "source": [
                "### GPUs, HF Cache"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "414198ee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "env: CUDA_VISIBLE_DEVICES=1\n",
                        "JSONDict(\"/home/stu235269/.config/Ultralytics/settings.json\"):\n",
                        "{\n",
                        "  \"settings_version\": \"0.0.6\",\n",
                        "  \"datasets_dir\": \"/data22/stu235269/datasets\",\n",
                        "  \"weights_dir\": \"/data22/stu235269/TinyML-MT/weights\",\n",
                        "  \"runs_dir\": \"/data22/stu235269/TinyML-MT/runs\",\n",
                        "  \"uuid\": \"99dfe128dbd9c89f330abe5241cca75f9c72d113cae99d1255fe4ea3855718b6\",\n",
                        "  \"sync\": true,\n",
                        "  \"api_key\": \"\",\n",
                        "  \"openai_api_key\": \"\",\n",
                        "  \"clearml\": true,\n",
                        "  \"comet\": true,\n",
                        "  \"dvc\": true,\n",
                        "  \"hub\": true,\n",
                        "  \"mlflow\": true,\n",
                        "  \"neptune\": true,\n",
                        "  \"raytune\": true,\n",
                        "  \"tensorboard\": false,\n",
                        "  \"wandb\": true,\n",
                        "  \"vscode_msg\": true,\n",
                        "  \"openvino_msg\": false\n",
                        "}\n",
                        "💡 Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n",
                        "../../.cache\n",
                        "Maats\n",
                        "\u001b[1morgs: \u001b[0m DBD-research-group,Basket-AEye\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "%matplotlib inline \n",
                "\n",
                "# Model\n",
                "%env CUDA_VISIBLE_DEVICES=1\n",
                "#%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32\n",
                "!yolo settings wandb=True\n",
                "\n",
                "# HF Cache\n",
                "os.environ[\"HF_HOME\"] = \"../../.cache\"\n",
                "!echo $HF_HOME\n",
                "!huggingface-cli whoami"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39be4fe6",
            "metadata": {},
            "source": [
                "### HP Settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "6cbc15dd",
            "metadata": {},
            "outputs": [],
            "source": [
                "IMG_SIZE = 500\n",
                "EPOCHS = 1\n",
                "DATASET_PATH = \"../../huggingface/mvtec_yolo/dataset.yaml\"\n",
                "DATASET_PATH = os.path.abspath(DATASET_PATH)\n",
                "NAME = \"mvtec\" # For WANDB (YOLO11n-COCO11-on_mvtec_train_with_augmented)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "07bb669e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def log_class_metrics_heatmap(val_results, null_classes=[], wandb_key=\"class_metrics_heatmap\"):\n",
                "    \"\"\"\n",
                "    Erstellt eine Heatmap aus den Klassenspezifischen Metriken (Precision, Recall, F1, AP@0.5)\n",
                "    aus den val_results eines YOLOv8-Modells und loggt sie zu Weights & Biases.\n",
                "    Diese Version ist robust gegenüber fehlenden Klassen im Val-Set.\n",
                "    \n",
                "    Parameter: \n",
                "        val_results: Das Ergebnisobjekt von model.val()\n",
                "        wandb_key (str): Der Key unter dem das Bild bei W&B geloggt wird\n",
                "    \"\"\"\n",
                "    import numpy as np\n",
                "    import matplotlib.pyplot as plt\n",
                "    import wandb\n",
                "\n",
                "    # Klassennamen sortiert\n",
                "    names_dict = val_results.names\n",
                "    sorted_class_ids_and_names = sorted(names_dict.items())\n",
                "    print(\"sorted_class_ids_and_names \", sorted_class_ids_and_names)\n",
                "    \n",
                "    map_id_on_result_id = {}\n",
                "    count = 0\n",
                "    for i, name in sorted_class_ids_and_names:\n",
                "        if name in null_classes:\n",
                "            map_id_on_result_id[i] = None \n",
                "        else:\n",
                "            map_id_on_result_id[i] = count\n",
                "            count += 1\n",
                "        \n",
                "    names = [name for _, name in sorted_class_ids_and_names if name not in null_classes]\n",
                "    class_ids = [i for i, _ in sorted_class_ids_and_names]\n",
                "\n",
                "    # Zugriff auf Metriken\n",
                "    p = val_results.box.p if hasattr(val_results.box, 'p') else []\n",
                "    r = val_results.box.r if hasattr(val_results.box, 'r') else []\n",
                "    f1 = val_results.box.f1 if hasattr(val_results.box, 'f1') else []\n",
                "    ap = val_results.box.all_ap if hasattr(val_results.box, 'all_ap') else []\n",
                "\n",
                "    # Hilfsfunktion zum sicheren Zugriff\n",
                "    def safe_get(metric_list, idx, default=0.0):\n",
                "        return metric_list[idx] if idx < len(metric_list) else default\n",
                "\n",
                "    def safe_ap0(metric_list, idx):\n",
                "        return metric_list[idx][0] if idx < len(metric_list) and len(metric_list[idx]) > 0 else 0.0\n",
                "\n",
                "    # Metriken extrahieren pro Klasse\n",
                "    precisions = [safe_get(p, map_id_on_result_id[i]) for i in class_ids if map_id_on_result_id[i] != None]\n",
                "    recalls = [safe_get(r, map_id_on_result_id[i]) for i in class_ids if map_id_on_result_id[i] != None]\n",
                "    f1s = [safe_get(f1, map_id_on_result_id[i]) for i in class_ids if map_id_on_result_id[i] != None]\n",
                "    ap50s = [safe_ap0(ap, map_id_on_result_id[i]) for i in class_ids if map_id_on_result_id[i] != None]\n",
                "\n",
                "    metrics_matrix = np.array([\n",
                "        precisions,\n",
                "        recalls,\n",
                "        f1s,\n",
                "        ap50s\n",
                "    ])\n",
                "\n",
                "    metric_names = ['Precision', 'Recall', 'F1', 'AP@0.5']\n",
                "\n",
                "    # Heatmap erzeugen\n",
                "    fig, ax = plt.subplots(figsize=(max(8, len(names) * 0.8), 4))\n",
                "    im = ax.imshow(metrics_matrix, cmap='viridis', vmin=0, vmax=1)\n",
                "\n",
                "    ax.set_xticks(np.arange(len(names)))\n",
                "    ax.set_xticklabels(names, rotation=45, ha=\"right\")\n",
                "    ax.set_yticks(np.arange(len(metric_names)))\n",
                "    ax.set_yticklabels(metric_names)\n",
                "\n",
                "    for i in range(metrics_matrix.shape[0]):\n",
                "        for j in range(metrics_matrix.shape[1]):\n",
                "            ax.text(j, i, f\"{metrics_matrix[i, j]:.2f}\", ha=\"center\", va=\"center\",\n",
                "                    color=\"white\" if metrics_matrix[i, j] < 0.5 else \"black\")\n",
                "\n",
                "    plt.colorbar(im, ax=ax)\n",
                "    plt.title(\"Metriken pro Klasse\")\n",
                "    plt.tight_layout()\n",
                "\n",
                "    wandb.log({wandb_key: wandb.Image(fig)})\n",
                "\n",
                "    plt.close(fig)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8d4c0689",
            "metadata": {},
            "source": [
                "## Training YOLO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "b2ff4a9a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatsaustralia\u001b[0m (\u001b[33mmaats\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.19.4"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/data22/stu235269/TinyML-MT/code_training/classification-code/wandb/run-20250620_003540-bgnxulh1</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1' target=\"_blank\">mvtec20Jun-00:35:39</a></strong> to <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Run ID: bgnxulh1\n",
                        "New https://pypi.org/project/ultralytics/8.3.156 available 😃 Update with 'pip install -U ultralytics'\n",
                        "Ultralytics 8.3.144 🚀 Python-3.10.12 torch-2.5.1+cu124 CUDA:0 (NVIDIA TITAN Xp, 12183MiB)\n",
                        "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=0.7, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/data22/stu235269/TinyML-MT/huggingface/mvtec_yolo/dataset.yaml, degrees=0.0, deterministic=True, device=1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=500, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=mvtec20Jun-00:35:39, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=3, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Yolo-Training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=Yolo-Training/mvtec20Jun-00:35:39, save_frames=False, save_json=False, save_period=3, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
                        "Overriding model.yaml nc=80 with nc=60\n",
                        "\n",
                        "                   from  n    params  module                                       arguments                     \n",
                        "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
                        "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
                        "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
                        "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
                        "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
                        "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
                        "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
                        "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
                        "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
                        "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
                        " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
                        " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
                        " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
                        " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
                        " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
                        " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
                        " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
                        " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
                        " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
                        " 23        [16, 19, 22]  1    442372  ultralytics.nn.modules.head.Detect           [60, [64, 128, 256]]          \n",
                        "YOLO11n summary: 181 layers, 2,601,540 parameters, 2,601,524 gradients, 6.5 GFLOPs\n",
                        "\n",
                        "Transferred 448/499 items from pretrained weights\n",
                        "Freezing layer 'model.23.dfl.conv.weight'\n",
                        "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
                        "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2770.8±388.7 MB/s, size: 270.5 KB)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data22/stu235269/TinyML-MT/huggingface/mvtec_yolo/labels/train.cache... 11380 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11380/11380 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=512 at 70.0% CUDA memory utilization.\n",
                        "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:1 (NVIDIA TITAN Xp) 11.90G total, 0.12G reserved, 0.06G allocated, 11.72G free\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
                        "     2601540       4.163         0.484         38.93         122.5        (1, 3, 512, 512)                    list\n",
                        "     2601540       8.325         0.644         28.71         83.73        (2, 3, 512, 512)                    list\n",
                        "     2601540       16.65         0.921         31.04         103.9        (4, 3, 512, 512)                    list\n",
                        "     2601540        33.3         1.321         34.66         69.75        (8, 3, 512, 512)                    list\n",
                        "     2601540        66.6         2.261         38.73         94.49       (16, 3, 512, 512)                    list\n",
                        "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 65 for CUDA:1 8.13G/11.90G (68%) ✅\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2271.6±1134.7 MB/s, size: 293.0 KB)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data22/stu235269/TinyML-MT/huggingface/mvtec_yolo/labels/train.cache... 11380 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11380/11380 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1597.0±810.3 MB/s, size: 248.9 KB)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mval: \u001b[0mScanning /data22/stu235269/TinyML-MT/huggingface/mvtec_yolo/labels/val.cache... 6600 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6600/6600 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Plotting labels to Yolo-Training/mvtec20Jun-00:35:39/labels.jpg... \n",
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000156, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005078125), 87 bias(decay=0.0)\n",
                        "Image sizes 512 train, 512 val\n",
                        "Using 8 dataloader workers\n",
                        "Logging results to \u001b[1mYolo-Training/mvtec20Jun-00:35:39\u001b[0m\n",
                        "Starting training for 1 epochs...\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "        1/1      6.26G     0.8173      4.501      1.112         40        512: 100%|██████████| 176/176 [01:31<00:00,  1.92it/s]\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.\n",
                        "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:40<00:00,  1.27it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                   all       6600      38422      0.198      0.113        0.1     0.0898\n",
                        "\n",
                        "1 epochs completed in 0.039 hours.\n",
                        "Optimizer stripped from Yolo-Training/mvtec20Jun-00:35:39/weights/last.pt, 5.5MB\n",
                        "Optimizer stripped from Yolo-Training/mvtec20Jun-00:35:39/weights/best.pt, 5.5MB\n",
                        "\n",
                        "Validating Yolo-Training/mvtec20Jun-00:35:39/weights/best.pt...\n",
                        "Ultralytics 8.3.144 🚀 Python-3.10.12 torch-2.5.1+cu124 CUDA:1 (NVIDIA TITAN Xp, 12183MiB)\n",
                        "YOLO11n summary (fused): 100 layers, 2,593,852 parameters, 0 gradients, 6.4 GFLOPs\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:37<00:00,  1.35it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                   all       6600      38422      0.198      0.112        0.1     0.0898\n",
                        "adelholzener_alpenquelle_classic_075        539        552      0.349      0.109       0.21        0.2\n",
                        "adelholzener_alpenquelle_naturell_075        526        553      0.113      0.599       0.21      0.198\n",
                        "adelholzener_classic_bio_apfelschorle_02        572        598     0.0309     0.0368     0.0125     0.0105\n",
                        "adelholzener_classic_naturell_02        511        707     0.0329     0.0679     0.0223      0.018\n",
                        "adelholzener_gourmet_mineralwasser_02        688        737          0          0    0.00973    0.00864\n",
                        "augustiner_lagerbraeu_hell_05        540        565          0          0      0.005    0.00333\n",
                        "augustiner_weissbier_05        662        779        0.1     0.0385     0.0415     0.0387\n",
                        "          coca_cola_05        478        494          0          0     0.0286     0.0251\n",
                        "    coca_cola_light_05        633        684     0.0115     0.0395     0.0183     0.0159\n",
                        "suntory_gokuri_lemonade        550        808    0.00638    0.00248      0.054     0.0432\n",
                        "    tegernseer_hell_03        568        585    0.00171    0.00171     0.0146      0.013\n",
                        "        corny_nussvoll        670        688    0.00517    0.00145     0.0285     0.0252\n",
                        " corny_nussvoll_single        640        742          0          0     0.0109    0.00993\n",
                        "   corny_schoko_banane        538        552          0          0    0.00106    0.00092\n",
                        "corny_schoko_banane_single        679        765          0          0     0.0253     0.0218\n",
                        "dr_oetker_vitalis_knuspermuesli_klassisch        732        757     0.0444      0.223     0.0388     0.0345\n",
                        "koelln_muesli_fruechte        604        627     0.0873    0.00159     0.0251     0.0218\n",
                        "  koelln_muesli_schoko        607        625     0.0524     0.0064     0.0536     0.0476\n",
                        "           caona_cocoa        590        610      0.321      0.256      0.249      0.226\n",
                        "          cocoba_cocoa        715        855          1          0     0.0218     0.0203\n",
                        "cafe_wunderbar_espresso        680        711      0.316     0.0886      0.145      0.138\n",
                        "douwe_egberts_professional_ground_coffee        651        731      0.115      0.159     0.0643       0.06\n",
                        "  gepa_bio_caffe_crema        622        647      0.316     0.0572      0.154      0.148\n",
                        "gepa_italienischer_bio_espresso        697        725          0          0     0.0148     0.0133\n",
                        " apple_braeburn_bundle        604        615      0.036    0.00976     0.0211     0.0198\n",
                        "apple_golden_delicious        607        655      0.168      0.786      0.371       0.33\n",
                        "    apple_granny_smith        475        519      0.349     0.0925      0.158      0.152\n",
                        "     apple_red_boskoop        541        708      0.216      0.459      0.236       0.23\n",
                        "               avocado        598        671      0.187     0.0134     0.0805     0.0761\n",
                        "         banana_bundle        527        527       0.84      0.556        0.7      0.579\n",
                        "         banana_single        553        565          0          0      0.119     0.0914\n",
                        "            clementine        606        631      0.448      0.579      0.506      0.451\n",
                        "     clementine_single        773        904      0.826    0.00996      0.356       0.33\n",
                        "grapes_green_sugraone_seedless        477        510          0          0     0.0106    0.00837\n",
                        "grapes_sweet_celebration_seedless        518        536          0          0    0.00753    0.00517\n",
                        "                  kiwi        620        633      0.143      0.267       0.11     0.0997\n",
                        "         orange_single        438        489      0.226      0.173      0.141      0.135\n",
                        "               oranges        447        469          0          0      0.046     0.0371\n",
                        "                  pear        488        532      0.074      0.091     0.0665     0.0445\n",
                        "pasta_reggia_elicoidali        471        485          0          0    0.00641    0.00542\n",
                        "  pasta_reggia_fusilli        704        726     0.0713       0.58     0.0942     0.0831\n",
                        "pasta_reggia_spaghetti        562        586     0.0606     0.0324     0.0264     0.0234\n",
                        " franken_tafelreiniger        700        804    0.00792    0.00124     0.0135     0.0102\n",
                        "pelikan_tintenpatrone_canon        608        657     0.0204    0.00609     0.0253     0.0223\n",
                        "ethiquable_gruener_tee_ceylon        566        710          1          0     0.0229     0.0192\n",
                        "gepa_bio_und_fair_fencheltee        578        593          1          0    0.00626    0.00556\n",
                        "gepa_bio_und_fair_kamillentee        498        513          0          0   0.000958   0.000958\n",
                        "gepa_bio_und_fair_kraeuterteemischung        598        610          1          0     0.0585      0.052\n",
                        "gepa_bio_und_fair_pfefferminztee        583        661    0.00301     0.0106      0.013     0.0117\n",
                        "gepa_bio_und_fair_rooibostee        560        637          0          0    0.00553     0.0052\n",
                        "kilimanjaro_tea_earl_grey        631        720    0.00289    0.00556     0.0153     0.0129\n",
                        "              cucumber        591        608          0          0     0.0249      0.022\n",
                        "                carrot        506        673          1          0     0.0238      0.022\n",
                        "            corn_salad        547        562    0.00634    0.00534      0.025     0.0201\n",
                        "               lettuce        528        550      0.441      0.813        0.6      0.557\n",
                        "         vine_tomatoes        658        678      0.126     0.0143     0.0606     0.0427\n",
                        "    roma_vine_tomatoes        493        512      0.041    0.00391     0.0255     0.0215\n",
                        "                rocket        615        628      0.139      0.129     0.0842     0.0739\n",
                        "         salad_iceberg        684        705      0.506      0.418      0.461      0.424\n",
                        "              zucchini        700        743     0.0137    0.00538     0.0252      0.023\n",
                        "Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
                        "Results saved to \u001b[1mYolo-Training/mvtec20Jun-00:35:39\u001b[0m\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁</td></tr><tr><td>lr/pg1</td><td>▁</td></tr><tr><td>lr/pg2</td><td>▁</td></tr><tr><td>metrics/mAP50(B)</td><td>█▁</td></tr><tr><td>metrics/mAP50-95(B)</td><td>█▁</td></tr><tr><td>metrics/precision(B)</td><td>█▁</td></tr><tr><td>metrics/recall(B)</td><td>█▁</td></tr><tr><td>model/GFLOPs</td><td>▁▁</td></tr><tr><td>model/parameters</td><td>▁▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁█</td></tr><tr><td>train/box_loss</td><td>▁</td></tr><tr><td>train/cls_loss</td><td>▁</td></tr><tr><td>train/dfl_loss</td><td>▁</td></tr><tr><td>val/box_loss</td><td>▁</td></tr><tr><td>val/cls_loss</td><td>▁</td></tr><tr><td>val/dfl_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>5e-05</td></tr><tr><td>lr/pg1</td><td>5e-05</td></tr><tr><td>lr/pg2</td><td>5e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.1001</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.08982</td></tr><tr><td>metrics/precision(B)</td><td>0.19758</td></tr><tr><td>metrics/recall(B)</td><td>0.11247</td></tr><tr><td>model/GFLOPs</td><td>6.504</td></tr><tr><td>model/parameters</td><td>2601540</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.504</td></tr><tr><td>train/box_loss</td><td>0.81733</td></tr><tr><td>train/cls_loss</td><td>4.50126</td></tr><tr><td>train/dfl_loss</td><td>1.11169</td></tr><tr><td>val/box_loss</td><td>0.54675</td></tr><tr><td>val/cls_loss</td><td>3.69877</td></tr><tr><td>val/dfl_loss</td><td>0.93323</td></tr></table><br/></div></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">mvtec20Jun-00:35:39</strong> at: <a href='https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1</a><br> View project at: <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a><br>Synced 5 W&B file(s), 27 media file(s), 10 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20250620_003540-bgnxulh1/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.19.4"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/data22/stu235269/TinyML-MT/code_training/classification-code/wandb/run-20250620_003912-bgnxulh1</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Resuming run <strong><a href='https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1' target=\"_blank\">mvtec20Jun-00:35:39</a></strong> to <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "sorted_class_ids_and_names  [(0, 'adelholzener_alpenquelle_classic_075'), (1, 'adelholzener_alpenquelle_naturell_075'), (2, 'adelholzener_classic_bio_apfelschorle_02'), (3, 'adelholzener_classic_naturell_02'), (4, 'adelholzener_gourmet_mineralwasser_02'), (5, 'augustiner_lagerbraeu_hell_05'), (6, 'augustiner_weissbier_05'), (7, 'coca_cola_05'), (8, 'coca_cola_light_05'), (9, 'suntory_gokuri_lemonade'), (10, 'tegernseer_hell_03'), (11, 'corny_nussvoll'), (12, 'corny_nussvoll_single'), (13, 'corny_schoko_banane'), (14, 'corny_schoko_banane_single'), (15, 'dr_oetker_vitalis_knuspermuesli_klassisch'), (16, 'koelln_muesli_fruechte'), (17, 'koelln_muesli_schoko'), (18, 'caona_cocoa'), (19, 'cocoba_cocoa'), (20, 'cafe_wunderbar_espresso'), (21, 'douwe_egberts_professional_ground_coffee'), (22, 'gepa_bio_caffe_crema'), (23, 'gepa_italienischer_bio_espresso'), (24, 'apple_braeburn_bundle'), (25, 'apple_golden_delicious'), (26, 'apple_granny_smith'), (27, 'apple_red_boskoop'), (28, 'avocado'), (29, 'banana_bundle'), (30, 'banana_single'), (31, 'clementine'), (32, 'clementine_single'), (33, 'grapes_green_sugraone_seedless'), (34, 'grapes_sweet_celebration_seedless'), (35, 'kiwi'), (36, 'orange_single'), (37, 'oranges'), (38, 'pear'), (39, 'pasta_reggia_elicoidali'), (40, 'pasta_reggia_fusilli'), (41, 'pasta_reggia_spaghetti'), (42, 'franken_tafelreiniger'), (43, 'pelikan_tintenpatrone_canon'), (44, 'ethiquable_gruener_tee_ceylon'), (45, 'gepa_bio_und_fair_fencheltee'), (46, 'gepa_bio_und_fair_kamillentee'), (47, 'gepa_bio_und_fair_kraeuterteemischung'), (48, 'gepa_bio_und_fair_pfefferminztee'), (49, 'gepa_bio_und_fair_rooibostee'), (50, 'kilimanjaro_tea_earl_grey'), (51, 'cucumber'), (52, 'carrot'), (53, 'corn_salad'), (54, 'lettuce'), (55, 'vine_tomatoes'), (56, 'roma_vine_tomatoes'), (57, 'rocket'), (58, 'salad_iceberg'), (59, 'zucchini')]\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>5e-05</td></tr><tr><td>lr/pg1</td><td>5e-05</td></tr><tr><td>lr/pg2</td><td>5e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.1001</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.08982</td></tr><tr><td>metrics/precision(B)</td><td>0.19758</td></tr><tr><td>metrics/recall(B)</td><td>0.11247</td></tr><tr><td>model/GFLOPs</td><td>6.504</td></tr><tr><td>model/parameters</td><td>2601540</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.504</td></tr><tr><td>train/box_loss</td><td>0.81733</td></tr><tr><td>train/cls_loss</td><td>4.50126</td></tr><tr><td>train/dfl_loss</td><td>1.11169</td></tr><tr><td>val/box_loss</td><td>0.54675</td></tr><tr><td>val/cls_loss</td><td>3.69877</td></tr><tr><td>val/dfl_loss</td><td>0.93323</td></tr></table><br/></div></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">mvtec20Jun-00:35:39</strong> at: <a href='https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/bgnxulh1</a><br> View project at: <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20250620_003912-bgnxulh1/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "done\n"
                    ]
                }
            ],
            "source": [
                "from ultralytics import YOLO\n",
                "import wandb\n",
                "from datetime import datetime\n",
                "import wandb\n",
                "NAME_RUN = NAME+datetime.now().strftime(\"%d%b-%H:%M:%S\")\n",
                "# WANB Init with custom name \n",
                "run = wandb.init(\n",
                "    project=\"Yolo-Training\",\n",
                "    entity=\"maats\",\n",
                "    name=NAME_RUN,\n",
                "    config={  # alle Hyperparameter sauber abspeichern\n",
                "        \"epochs\": EPOCHS,\n",
                "        \"imgsz\": IMG_SIZE,\n",
                "        \"model\": \"yolo11n.pt\",\n",
                "        \"dataset\": DATASET_PATH,\n",
                "    },\n",
                "    sync_tensorboard=True,\n",
                ")\n",
                "print(f\"Run ID: {run.id}\")\n",
                "try:\n",
                "    # YOLO-Model load\n",
                "    model = YOLO(\"yolo11n.pt\")\n",
                "\n",
                "    # Training\n",
                "    results = model.train(\n",
                "        data=DATASET_PATH,\n",
                "        epochs=EPOCHS,\n",
                "        imgsz=IMG_SIZE,\n",
                "        project=\"Yolo-Training\",\n",
                "        name=NAME_RUN,\n",
                "        verbose=True,\n",
                "        val=True,\n",
                "        save=True,\n",
                "        save_period=3,\n",
                "        mode=\"wandb\",\n",
                "        batch=0.70, # 70% ? Check this\n",
                "        patience=3, # Early Stopping Patience\n",
                "        pretrained=True, #! Pretrained Model\n",
                "        multi_scale=False, #! Test this\n",
                "        cos_lr=False, #! Test this\n",
                "        freeze=None, #! Test this\n",
                "        #hsv_h=0.1,\n",
                "        #degrees=180,\n",
                "        #shear=10,\n",
                "        #perspective=0.0003,\n",
                "        #mixup = 0.3, # das was Jannek meinte \n",
                "        #cutmix = 0.3,\n",
                "        #copy_paste = 0.1, # weis ja nicht ...\n",
                "    )\n",
                "    wandb.init(id=run.id, resume=\"allow\", project=\"Yolo-Training\")\n",
                "    wandb.config.update(model.args) # Log all settings to WANDB\n",
                "\n",
                "    #best_model_path = f\"Yolo-Training/{NAME_RUN}/weights/best.pt\"\n",
                "    #model = YOLO(best_model_path)\n",
                "\n",
                "    #val_results = model.val(data=DATASET_PATH, imgsz=IMG_SIZE) Already done in train\n",
                "    log_class_metrics_heatmap(results)\n",
                "except Exception as e:\n",
                "    print(f\"An error occurred: {e}\")\n",
                "\n",
                "finally:\n",
                "    wandb.finish()\n",
                "    print(\"done\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b20db8b0",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "2f5a91d3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best models\n",
                "best_model_path = f\"runs/train/{NAME_RUN}/weights/best.pt\"\n",
                "model = YOLO(best_model_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3697ef6b",
            "metadata": {},
            "source": [
                "## MVTEC Grids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "030f9f16",
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "# Load best model\n",
                "MODEL_PATH = \"runs/train/artificial_created_mult_back_rotated_big_yolol18Jun-00:13:53/weights/best.pt\"\n",
                "model = YOLO(MODEL_PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "0f268df5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtorge-schwark\u001b[0m (\u001b[33mmaats\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.19.4"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/data22/stu236894/GitRepos/TinyML-MT/code_training/classification-code/wandb/run-20250618_102839-h399va08</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Resuming run <strong><a href='https://wandb.ai/maats/Yolo-Training/runs/h399va08' target=\"_blank\">artificial_created_mult_back_rotated_big_yolol18Jun-00:13:53</a></strong> to <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/maats/Yolo-Training/runs/h399va08' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/h399va08</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/maats/Yolo-Training/runs/h399va08?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x7f48a0d59cf0>"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import wandb\n",
                "\n",
                "# Deine Run-ID, z. B. \"ls3jwotb\" aus der URL oder dem lokalen Log\n",
                "run_id = \"h399va08\"\n",
                "\n",
                "# Reaktiviere den Run\n",
                "wandb.init(\n",
                "    project=\"Yolo-Training\",\n",
                "    entity=\"maats\",\n",
                "    id=run_id,\n",
                "    resume=\"allow\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "966a9428",
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../../huggingface/mvtec_annotated/labels'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Modell laden (ggf. Pfad anpassen)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#model = YOLO(\"runs/train/YOLO11n-COCO11-first_artificial_created_dataset/weights/best.pt\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 1.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# image_paths, _ = im_script.get_mvtec_images_for_first_artificial_dataset_classes_trained_on_10_clases()\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m image_paths, _ \u001b[38;5;241m=\u001b[39m \u001b[43mim_script\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mvtec_images_for_10classes_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     23\u001b[0m num_grids \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
                        "File \u001b[0;32m/data22/stu235269/TinyML-MT/code_training/classification-code/find_usefull_images_scripts.py:77\u001b[0m, in \u001b[0;36mget_mvtec_images_for_10classes_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m class_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m26\u001b[39m, \u001b[38;5;241m27\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m29\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m44\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m46\u001b[39m, \u001b[38;5;241m47\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m49\u001b[39m, \u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# there is no lemen oat meal or tomato souce in mvtec\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m image_paths, label_lines \u001b[38;5;241m=\u001b[39m \u001b[43mget_mvtec_with_classes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../huggingface/mvtec_annotated/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotation_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../huggingface/mvtec_annotated/labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_ids\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_paths, label_lines\n",
                        "File \u001b[0;32m/data22/stu235269/TinyML-MT/code_training/classification-code/find_usefull_images_scripts.py:7\u001b[0m, in \u001b[0;36mget_mvtec_with_classes\u001b[0;34m(class_list, image_path, annotation_path, map_ids)\u001b[0m\n\u001b[1;32m      4\u001b[0m valid_image_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m valid_labels \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Liste von Listen: Jede innere Liste enthält Labelzeilen für ein Bild\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotation_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      8\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(annotation_path, subfolder)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path):\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../huggingface/mvtec_annotated/labels'"
                    ]
                }
            ],
            "source": [
                "import wandb\n",
                "from ultralytics import YOLO\n",
                "import find_usefull_images_scripts as im_script\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Modell laden (ggf. Pfad anpassen)\n",
                "#model = YOLO(\"runs/train/YOLO11n-COCO11-first_artificial_created_dataset/weights/best.pt\")\n",
                "\n",
                "# Alle Beispielbilder laden\n",
                "# image_paths, _ = im_script.get_mvtec_images_for_first_artificial_dataset_classes()\n",
                "\n",
                "\n",
                "# 1.\n",
                "# image_paths, _ = im_script.get_mvtec_images_for_first_artificial_dataset_classes_trained_on_10_clases()\n",
                "\n",
                "\n",
                "image_paths, _ = im_script.get_mvtec_images_for_10classes_dataset()\n",
                "\n",
                "\n",
                "batch_size = 20\n",
                "num_grids = 10\n",
                "\n",
                "for grid_idx in range(num_grids):\n",
                "    start_idx = grid_idx * batch_size\n",
                "    end_idx = start_idx + batch_size\n",
                "    selected_paths = image_paths[start_idx:end_idx]\n",
                "\n",
                "    # Vorhersagen durchführen (Batch)\n",
                "    preds = model.predict(\n",
                "        selected_paths,\n",
                "        imgsz=IMG_SIZE,\n",
                "        save=False,\n",
                "        stream=False\n",
                "    )\n",
                "\n",
                "    # Bilder vorbereiten\n",
                "    images_drawn = []\n",
                "    for img_path, pred in zip(selected_paths, preds):\n",
                "        img = cv2.imread(str(img_path))\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "        h, w, _ = img.shape\n",
                "        for box, cls, conf in zip(pred.boxes.xyxy, pred.boxes.cls, pred.boxes.conf):\n",
                "            x1, y1, x2, y2 = map(int, box)\n",
                "            class_name = model.names[int(cls)]\n",
                "            label = f\"{class_name} {conf:.2f}\"\n",
                "\n",
                "            # Rechteck zeichnen\n",
                "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
                "\n",
                "            # Textgröße bestimmen\n",
                "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
                "            font_scale = 1.2\n",
                "            thickness = 2\n",
                "            (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
                "\n",
                "            # Textposition\n",
                "            text_x = x1\n",
                "            if y1 - text_h - baseline > 0:\n",
                "                text_y = y1 - 5\n",
                "                # Hintergrundrechteck für Text (oben)\n",
                "                cv2.rectangle(img, (text_x, text_y - text_h - baseline), (text_x + text_w, text_y + baseline), (0, 255, 0), cv2.FILLED)\n",
                "                cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n",
                "            else:\n",
                "                text_y = y2 + text_h + 5\n",
                "                if text_y > h:\n",
                "                    text_y = y2 - 5\n",
                "                # Hintergrundrechteck für Text (unten)\n",
                "                cv2.rectangle(img, (text_x, text_y - text_h - baseline), (text_x + text_w, text_y + baseline), (0, 255, 0), cv2.FILLED)\n",
                "                cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n",
                "\n",
                "        images_drawn.append(img)\n",
                "\n",
                "    # 5x4 Grid erstellen\n",
                "    rows, cols = 5, 4\n",
                "    fig, axs = plt.subplots(rows, cols, figsize=(12, 15), dpi=300)\n",
                "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, hspace=0.05, wspace=0.05)\n",
                "\n",
                "    for i, ax in enumerate(axs.flat):\n",
                "        if i < len(images_drawn):\n",
                "            ax.imshow(images_drawn[i])\n",
                "            ax.axis('off')\n",
                "        else:\n",
                "            ax.axis('off')\n",
                "\n",
                "    # Grid als Bild speichern\n",
                "    grid_img_path = f\"prediction_grid_{grid_idx+1}.jpg\"\n",
                "    fig.savefig(grid_img_path, bbox_inches='tight', pad_inches=0)\n",
                "    plt.close(fig)\n",
                "\n",
                "    # Bild bei wandb loggen\n",
                "    wandb.log({f\"mvtec/grids/prediction_grid{grid_idx+1}\": wandb.Image(grid_img_path)})\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cd112dc0",
            "metadata": {},
            "source": [
                "## MVTEC Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cbbd30d0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "Ultralytics 8.3.129 🚀 Python-3.10.12 torch-2.5.1+cu124 CUDA:0 (NVIDIA TITAN Xp, 12183MiB)\n",
                        "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1946.2±996.5 MB/s, size: 142.6 KB)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mval: \u001b[0mScanning /data22/stu236894/GitRepos/TinyML-MT/huggingface/full_classes_trained_on_10classes/labels/test.cache... 2124 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2124/2124 [00:00<?, ?it/s]\n",
                        "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 133/133 [00:13<00:00, 10.22it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                   all       2124       3884      0.375       0.52      0.349      0.131\n",
                        "                 apple        230        656      0.411      0.514      0.434       0.15\n",
                        "               avocado        150        270      0.374      0.784       0.37      0.127\n",
                        "                banana         53         54     0.0822      0.537     0.0982     0.0304\n",
                        "                coffee        604        879      0.286      0.734       0.36      0.165\n",
                        "              cucumber         91         91      0.531       0.56       0.58      0.169\n",
                        "             fruit tea        767       1538      0.507      0.269      0.304      0.133\n",
                        "                 pasta        391        396      0.435      0.245      0.295      0.145\n",
                        "Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
                        "Results saved to \u001b[1m/data22/stu236894/GitRepos/TinyML-MT/runs/detect/val67\u001b[0m\n",
                        "0.37501995669451427 0.5204666616041824 0.38957328338065833\n",
                        "sorted_class_ids_and_names  [(0, 'apple'), (1, 'avocado'), (2, 'banana'), (3, 'coffee'), (4, 'cucumber'), (5, 'fruit tea'), (6, 'lemon'), (7, 'oatmeal'), (8, 'pasta'), (9, 'tomato sauce')]\n"
                    ]
                }
            ],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "# Modell laden\n",
                "path = \"../../huggingface/full_classes_trained_on_10classes/dataset.yaml\"\n",
                "# null_classes for big \n",
                "null_clases = [\"lemon\", \"oatmeal\", \"tomato sauce\"]\n",
                "# for small dataset \n",
                "# null_clases = [\"coffee\", \"lemon\", \"oatmeal\", \"pasta\", \"tomato sauce\"]\n",
                "\n",
                "\n",
                "absolute_path = os.path.abspath(path)\n",
                "# Evaluation auf dem 'test' Teil des Datasets\n",
                "metrics = model.val(\n",
                "    data=absolute_path,  \n",
                "    split='test',              \n",
                "    imgsz=IMG_SIZE               \n",
                ")\n",
                "\n",
                "print(np.mean(metrics.box.p),np.mean(metrics.box.r), np.mean(metrics.box.f1))\n",
                "log_class_metrics_heatmap(metrics, null_classes= null_clases, wandb_key=\"mvtec/heatmap\")\n",
                "wandb.log({\n",
                "    \"mvtec/mAP50_class_normal\": float(metrics.box.map50),\n",
                "    \"mvtec/precision_class_normal\": float(np.mean(metrics.box.p)),\n",
                "    \"mvtec/recall_class_normal\": float(np.mean(metrics.box.r)),\n",
                "    \"mvtec/f1_class_normal\": float(np.mean(metrics.box.f1)),\n",
                "    \"mvtec/mAP50-95_class_normal\": float(metrics.box.map),\n",
                "})\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc1b1ecd",
            "metadata": {},
            "source": [
                "## CUSTOM Grid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3763fe9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 2 coffees, 1.1ms\n",
                        "1: 384x512 1 lemon, 1 tomato sauce, 1.1ms\n",
                        "2: 384x512 1 oatmeal, 1 pasta, 1.1ms\n",
                        "3: 384x512 2 coffees, 1.1ms\n",
                        "4: 384x512 1 apple, 1.1ms\n",
                        "5: 384x512 2 coffees, 1.1ms\n",
                        "6: 384x512 2 bananas, 1 coffee, 1 pasta, 1.1ms\n",
                        "7: 384x512 (no detections), 1.1ms\n",
                        "8: 384x512 1 avocado, 1 lemon, 1.1ms\n",
                        "9: 384x512 1 apple, 1 avocado, 1.1ms\n",
                        "10: 384x512 2 apples, 1.1ms\n",
                        "11: 384x512 1 avocado, 1 tomato sauce, 1.1ms\n",
                        "12: 384x512 1 coffee, 2 lemons, 1.1ms\n",
                        "13: 384x512 1 coffee, 1.1ms\n",
                        "14: 384x512 1 banana, 1.1ms\n",
                        "15: 384x512 1 coffee, 2 tomato sauces, 1.1ms\n",
                        "16: 384x512 1 coffee, 1 lemon, 1.1ms\n",
                        "17: 384x512 1 avocado, 1 coffee, 1 oatmeal, 1.1ms\n",
                        "18: 384x512 1 apple, 1 coffee, 1.1ms\n",
                        "19: 384x512 1 apple, 1 banana, 1 tomato sauce, 1.1ms\n",
                        "Speed: 3.4ms preprocess, 1.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 banana, 1 lemon, 1 pasta, 1.1ms\n",
                        "1: 384x512 1 avocado, 1 lemon, 1.1ms\n",
                        "2: 384x512 1 apple, 1.1ms\n",
                        "3: 384x512 1 apple, 1.1ms\n",
                        "4: 384x512 2 apples, 2 avocados, 1 fruit tea, 3 lemons, 1 oatmeal, 1.1ms\n",
                        "5: 384x512 1 lemon, 1.1ms\n",
                        "6: 384x512 2 apples, 1.1ms\n",
                        "7: 384x512 (no detections), 1.1ms\n",
                        "8: 384x512 2 avocados, 2 bananas, 2 coffees, 1 lemon, 1.1ms\n",
                        "9: 384x512 2 fruit teas, 1 oatmeal, 1.1ms\n",
                        "10: 384x512 1 coffee, 2 lemons, 1.1ms\n",
                        "11: 384x512 1 apple, 2 avocados, 1.1ms\n",
                        "12: 384x512 3 apples, 2 avocados, 1 fruit tea, 4 lemons, 1.1ms\n",
                        "13: 384x512 1 banana, 1.1ms\n",
                        "14: 384x512 2 apples, 2 bananas, 1 fruit tea, 1 lemon, 2 oatmeals, 1 pasta, 1.1ms\n",
                        "15: 384x512 1 avocado, 1 coffee, 1.1ms\n",
                        "16: 384x512 1 coffee, 1 tomato sauce, 1.1ms\n",
                        "17: 384x512 2 lemons, 1.1ms\n",
                        "18: 384x512 (no detections), 1.1ms\n",
                        "19: 384x512 1 pasta, 1.1ms\n",
                        "Speed: 2.0ms preprocess, 1.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 coffee, 1.2ms\n",
                        "1: 384x512 2 coffees, 1 tomato sauce, 1.2ms\n",
                        "2: 384x512 1 avocado, 3 coffees, 1.2ms\n",
                        "3: 384x512 2 tomato sauces, 1.2ms\n",
                        "4: 384x512 1 avocado, 1.2ms\n",
                        "5: 384x512 1 apple, 1 lemon, 1.2ms\n",
                        "6: 384x512 2 avocados, 4 lemons, 1.2ms\n",
                        "7: 384x512 1 pasta, 1.2ms\n",
                        "8: 384x512 1 banana, 1 lemon, 1.2ms\n",
                        "9: 384x512 1 avocado, 1 coffee, 1.2ms\n",
                        "10: 384x512 2 apples, 3 avocados, 3 lemons, 1.2ms\n",
                        "11: 384x512 1 apple, 2 avocados, 2 lemons, 1 pasta, 1.2ms\n",
                        "12: 384x512 3 coffees, 1.2ms\n",
                        "13: 384x512 1 pasta, 1.2ms\n",
                        "14: 384x512 1 fruit tea, 1.2ms\n",
                        "15: 384x512 1 pasta, 1.2ms\n",
                        "16: 384x512 1 coffee, 3 lemons, 1.2ms\n",
                        "17: 384x512 2 apples, 3 avocados, 5 lemons, 1 oatmeal, 1.2ms\n",
                        "18: 384x512 1 coffee, 2 tomato sauces, 1.2ms\n",
                        "19: 384x512 1 avocado, 1 tomato sauce, 1.2ms\n",
                        "Speed: 2.4ms preprocess, 1.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 banana, 1 tomato sauce, 1.1ms\n",
                        "1: 384x512 1 apple, 1 coffee, 1 tomato sauce, 1.1ms\n",
                        "2: 384x512 1 coffee, 1 fruit tea, 1 oatmeal, 1.1ms\n",
                        "3: 384x512 2 avocados, 2 coffees, 1 lemon, 1.1ms\n",
                        "4: 384x512 2 lemons, 1.1ms\n",
                        "5: 384x512 1 apple, 2 bananas, 1 coffee, 1.1ms\n",
                        "6: 384x512 1 coffee, 1 lemon, 1.1ms\n",
                        "7: 384x512 2 coffees, 1 cucumber, 1 tomato sauce, 1.1ms\n",
                        "8: 384x512 1 apple, 1 avocado, 1 lemon, 1 pasta, 1.1ms\n",
                        "9: 384x512 1 avocado, 1.1ms\n",
                        "10: 384x512 1 apple, 1 banana, 1 tomato sauce, 1.1ms\n",
                        "11: 384x512 1 tomato sauce, 1.1ms\n",
                        "12: 384x512 1 fruit tea, 1.1ms\n",
                        "13: 384x512 1 coffee, 1 lemon, 1.1ms\n",
                        "14: 384x512 1 avocado, 1 tomato sauce, 1.1ms\n",
                        "15: 384x512 2 bananas, 2 coffees, 1.1ms\n",
                        "16: 384x512 (no detections), 1.1ms\n",
                        "17: 384x512 1 apple, 1 avocado, 1 banana, 1 fruit tea, 1 lemon, 1.1ms\n",
                        "18: 384x512 2 apples, 1 banana, 1 tomato sauce, 1.1ms\n",
                        "19: 384x512 1 avocado, 1.1ms\n",
                        "Speed: 1.6ms preprocess, 1.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 apple, 2 cucumbers, 1 fruit tea, 3 lemons, 1 oatmeal, 1 tomato sauce, 1.1ms\n",
                        "1: 384x512 1 avocado, 1 tomato sauce, 1.1ms\n",
                        "2: 384x512 1 apple, 2 avocados, 1 lemon, 1 pasta, 1.1ms\n",
                        "3: 384x512 1 banana, 1 tomato sauce, 1.1ms\n",
                        "4: 384x512 1 coffee, 1 oatmeal, 1.1ms\n",
                        "5: 384x512 1 coffee, 1 oatmeal, 1 pasta, 1.1ms\n",
                        "6: 384x512 1 lemon, 2 oatmeals, 1 tomato sauce, 1.1ms\n",
                        "7: 384x512 1 pasta, 1.1ms\n",
                        "8: 384x512 1 tomato sauce, 1.1ms\n",
                        "9: 384x512 1 apple, 2 avocados, 1 coffee, 1.1ms\n",
                        "10: 384x512 2 apples, 1 lemon, 1.1ms\n",
                        "11: 384x512 1 banana, 1.1ms\n",
                        "12: 384x512 1 coffee, 1.1ms\n",
                        "13: 384x512 1 pasta, 1.1ms\n",
                        "14: 384x512 1 fruit tea, 1.1ms\n",
                        "15: 384x512 1 coffee, 1.1ms\n",
                        "16: 384x512 1 pasta, 1.1ms\n",
                        "17: 384x512 1 pasta, 1.1ms\n",
                        "18: 384x512 2 cucumbers, 1 lemon, 1 pasta, 1.1ms\n",
                        "19: 384x512 1 avocado, 3 coffees, 1 lemon, 1 pasta, 2 tomato sauces, 1.1ms\n",
                        "Speed: 1.6ms preprocess, 1.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 2 avocados, 2 lemons, 1.1ms\n",
                        "1: 384x512 1 apple, 2 avocados, 1 banana, 2 coffees, 1 lemon, 1 oatmeal, 1.1ms\n",
                        "2: 384x512 4 coffees, 1 lemon, 1.1ms\n",
                        "3: 384x512 1 avocado, 1 tomato sauce, 1.1ms\n",
                        "4: 384x512 2 lemons, 1.1ms\n",
                        "5: 384x512 2 apples, 2 avocados, 2 lemons, 1.1ms\n",
                        "6: 384x512 1 banana, 1 cucumber, 2 fruit teas, 2 lemons, 2 oatmeals, 1.1ms\n",
                        "7: 384x512 2 lemons, 4 oatmeals, 1.1ms\n",
                        "8: 384x512 1 banana, 2 lemons, 1.1ms\n",
                        "9: 384x512 1 coffee, 1 tomato sauce, 1.1ms\n",
                        "10: 384x512 1 fruit tea, 1.1ms\n",
                        "11: 384x512 2 fruit teas, 1.1ms\n",
                        "12: 384x512 1 banana, 1.1ms\n",
                        "13: 384x512 1 tomato sauce, 1.1ms\n",
                        "14: 384x512 1 avocado, 1 coffee, 1 lemon, 1 pasta, 1.1ms\n",
                        "15: 384x512 1 avocado, 3 coffees, 1 lemon, 1 pasta, 1.1ms\n",
                        "16: 384x512 1 apple, 1 coffee, 1.1ms\n",
                        "17: 384x512 3 coffees, 1.1ms\n",
                        "18: 384x512 2 apples, 1 cucumber, 1 fruit tea, 3 lemons, 1.1ms\n",
                        "19: 384x512 1 banana, 1.1ms\n",
                        "Speed: 1.5ms preprocess, 1.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 banana, 1 fruit tea, 1 oatmeal, 1.1ms\n",
                        "1: 384x512 4 avocados, 2 lemons, 1.1ms\n",
                        "2: 384x512 1 apple, 1 lemon, 1.1ms\n",
                        "3: 384x512 1 coffee, 2 lemons, 1.1ms\n",
                        "4: 384x512 1 apple, 2 bananas, 1 lemon, 1.1ms\n",
                        "5: 384x512 3 lemons, 1.1ms\n",
                        "6: 384x512 3 coffees, 1.1ms\n",
                        "7: 384x512 1 avocado, 1 lemon, 1.1ms\n",
                        "8: 384x512 1 banana, 1.1ms\n",
                        "9: 384x512 4 apples, 1 banana, 1.1ms\n",
                        "10: 384x512 1 coffee, 1 pasta, 1.1ms\n",
                        "11: 384x512 2 avocados, 1.1ms\n",
                        "12: 384x512 1 banana, 1.1ms\n",
                        "13: 384x512 2 avocados, 1.1ms\n",
                        "14: 384x512 1 pasta, 1 tomato sauce, 1.1ms\n",
                        "15: 384x512 2 oatmeals, 1.1ms\n",
                        "16: 384x512 1 pasta, 1.1ms\n",
                        "17: 384x512 1 coffee, 1 pasta, 1.1ms\n",
                        "18: 384x512 1 avocado, 1 coffee, 2 lemons, 1.1ms\n",
                        "19: 384x512 1 avocado, 1.1ms\n",
                        "Speed: 1.4ms preprocess, 1.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 coffee, 1.1ms\n",
                        "1: 384x512 1 coffee, 1.1ms\n",
                        "2: 384x512 1 apple, 2 avocados, 1.1ms\n",
                        "3: 384x512 1 avocado, 1 lemon, 1.1ms\n",
                        "4: 384x512 1 apple, 1 coffee, 1 tomato sauce, 1.1ms\n",
                        "5: 384x512 1 pasta, 1.1ms\n",
                        "6: 384x512 2 apples, 3 bananas, 1.1ms\n",
                        "7: 384x512 2 coffees, 1 lemon, 1 oatmeal, 1.1ms\n",
                        "8: 384x512 1 banana, 1 coffee, 1.1ms\n",
                        "9: 384x512 1 banana, 1.1ms\n",
                        "10: 384x512 1 coffee, 1 lemon, 1.1ms\n",
                        "11: 384x512 2 fruit teas, 1 oatmeal, 1.1ms\n",
                        "12: 384x512 2 avocados, 2 lemons, 1.1ms\n",
                        "13: 384x512 1 banana, 1.1ms\n",
                        "14: 384x512 1 banana, 1.1ms\n",
                        "15: 384x512 2 lemons, 2 oatmeals, 1.1ms\n",
                        "16: 384x512 1 avocado, 1 banana, 1.1ms\n",
                        "17: 384x512 1 apple, 1.1ms\n",
                        "18: 384x512 1 avocado, 2 lemons, 1.1ms\n",
                        "19: 384x512 2 tomato sauces, 1.1ms\n",
                        "Speed: 1.4ms preprocess, 1.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 2 cucumbers, 2 tomato sauces, 1.1ms\n",
                        "1: 384x512 2 coffees, 1 lemon, 1.1ms\n",
                        "2: 384x512 2 avocados, 1 tomato sauce, 1.1ms\n",
                        "3: 384x512 1 banana, 2 coffees, 1.1ms\n",
                        "4: 384x512 2 avocados, 2 lemons, 1.1ms\n",
                        "5: 384x512 3 lemons, 1.1ms\n",
                        "6: 384x512 1 banana, 1 tomato sauce, 1.1ms\n",
                        "7: 384x512 1 avocado, 1 coffee, 1 oatmeal, 1 tomato sauce, 1.1ms\n",
                        "8: 384x512 2 apples, 1 lemon, 1 oatmeal, 2 pastas, 1.1ms\n",
                        "9: 384x512 1 apple, 1 coffee, 2 fruit teas, 1.1ms\n",
                        "10: 384x512 1 coffee, 2 cucumbers, 2 lemons, 1 tomato sauce, 1.1ms\n",
                        "11: 384x512 2 avocados, 3 coffees, 1 pasta, 1.1ms\n",
                        "12: 384x512 1 avocado, 1.1ms\n",
                        "13: 384x512 2 avocados, 1 tomato sauce, 1.1ms\n",
                        "14: 384x512 1 apple, 1 fruit tea, 2 oatmeals, 1.1ms\n",
                        "15: 384x512 1 apple, 1 banana, 1 lemon, 1.1ms\n",
                        "16: 384x512 1 apple, 1 coffee, 1 tomato sauce, 1.1ms\n",
                        "17: 384x512 2 apples, 1 avocado, 1 lemon, 1 pasta, 1.1ms\n",
                        "18: 384x512 1 avocado, 4 bananas, 3 coffees, 1 lemon, 1.1ms\n",
                        "19: 384x512 1 banana, 1 lemon, 1.1ms\n",
                        "Speed: 1.6ms preprocess, 1.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "\n",
                        "WARNING ⚠️ imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
                        "0: 384x512 1 apple, 1 tomato sauce, 1.1ms\n",
                        "1: 384x512 1 banana, 2 lemons, 1.1ms\n",
                        "2: 384x512 (no detections), 1.1ms\n",
                        "3: 384x512 1 apple, 3 avocados, 1 lemon, 1 oatmeal, 1.1ms\n",
                        "4: 384x512 1 coffee, 1 lemon, 1.1ms\n",
                        "5: 384x512 1 apple, 2 tomato sauces, 1.1ms\n",
                        "6: 384x512 1 apple, 1 avocado, 2 cucumbers, 1 fruit tea, 1.1ms\n",
                        "7: 384x512 1 apple, 1 avocado, 1.1ms\n",
                        "8: 384x512 1 oatmeal, 1 pasta, 1.1ms\n",
                        "9: 384x512 1 tomato sauce, 1.1ms\n",
                        "10: 384x512 1 banana, 1.1ms\n",
                        "11: 384x512 1 banana, 1 lemon, 3 pastas, 1 tomato sauce, 1.1ms\n",
                        "12: 384x512 1 apple, 5 coffees, 2 cucumbers, 2 fruit teas, 3 lemons, 1.1ms\n",
                        "13: 384x512 2 lemons, 1.1ms\n",
                        "14: 384x512 1 coffee, 1 tomato sauce, 1.1ms\n",
                        "15: 384x512 1 apple, 1 tomato sauce, 1.1ms\n",
                        "16: 384x512 1 oatmeal, 1.1ms\n",
                        "17: 384x512 1 apple, 1.1ms\n",
                        "18: 384x512 1 coffee, 2 lemons, 1.1ms\n",
                        "19: 384x512 1 avocado, 2 coffees, 1 lemon, 1 tomato sauce, 1.1ms\n",
                        "Speed: 1.5ms preprocess, 1.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping banana tensor(2., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping pasta tensor(8., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping cucumber tensor(4., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping fruit tea tensor(5., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping oatmeal tensor(7., device='cuda:0')\n",
                        "mapping apple tensor(0., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping avocado tensor(1., device='cuda:0')\n",
                        "mapping lemon tensor(6., device='cuda:0')\n",
                        "mapping coffee tensor(3., device='cuda:0')\n",
                        "mapping tomato sauce tensor(9., device='cuda:0')\n"
                    ]
                }
            ],
            "source": [
                "import wandb\n",
                "from ultralytics import YOLO\n",
                "import find_usefull_images_scripts as im_script\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Alle Beispielbilder laden\n",
                "image_paths, _ = im_script.get_custom_10class_class_dataset()\n",
                "\n",
                "#image_paths, _ = im_script.get_custom_small_class_dataset()\n",
                "\n",
                "batch_size = 20\n",
                "num_grids = 10\n",
                "\n",
                "for grid_idx in range(num_grids):\n",
                "    start_idx = grid_idx * batch_size\n",
                "    end_idx = start_idx + batch_size\n",
                "    selected_paths = image_paths[start_idx:end_idx]\n",
                "\n",
                "    # Vorhersagen durchführen (Batch)\n",
                "    preds = model.predict(\n",
                "        selected_paths,\n",
                "        imgsz=IMG_SIZE,\n",
                "        save=False,\n",
                "        stream=False\n",
                "    )\n",
                "\n",
                "    # Bilder vorbereiten\n",
                "    images_drawn = []\n",
                "    for img_path, pred in zip(selected_paths, preds):\n",
                "        img = cv2.imread(str(img_path))\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "        h, w, _ = img.shape\n",
                "        for box, cls, conf in zip(pred.boxes.xyxy, pred.boxes.cls, pred.boxes.conf):\n",
                "            x1, y1, x2, y2 = map(int, box)\n",
                "\n",
                "            class_name = model.names[int(cls)]\n",
                "            print(\"mapping\" , class_name, cls)\n",
                "            label = f\"{class_name} {conf:.2f}\"\n",
                "\n",
                "            # Rechteck zeichnen\n",
                "            cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
                "\n",
                "            # Textgröße bestimmen\n",
                "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
                "            font_scale = 1.2\n",
                "            thickness = 2\n",
                "            (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
                "\n",
                "            # Textposition\n",
                "            text_x = x1\n",
                "            if y1 - text_h - baseline > 0:\n",
                "                text_y = y1 - 5\n",
                "                # Hintergrundrechteck für Text (oben)\n",
                "                cv2.rectangle(img, (text_x, text_y - text_h - baseline), (text_x + text_w, text_y + baseline), (0, 255, 0), cv2.FILLED)\n",
                "                cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n",
                "            else:\n",
                "                text_y = y2 + text_h + 5\n",
                "                if text_y > h:\n",
                "                    text_y = y2 - 5\n",
                "                # Hintergrundrechteck für Text (unten)\n",
                "                cv2.rectangle(img, (text_x, text_y - text_h - baseline), (text_x + text_w, text_y + baseline), (0, 255, 0), cv2.FILLED)\n",
                "                cv2.putText(img, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n",
                "\n",
                "        images_drawn.append(img)\n",
                "\n",
                "    # 5x4 Grid erstellen\n",
                "    rows, cols = 5, 4\n",
                "    fig, axs = plt.subplots(rows, cols, figsize=(12, 15), dpi=300)\n",
                "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, hspace=0.05, wspace=0.05)\n",
                "\n",
                "    for i, ax in enumerate(axs.flat):\n",
                "        if i < len(images_drawn):\n",
                "            ax.imshow(images_drawn[i])\n",
                "            ax.axis('off')\n",
                "        else:\n",
                "            ax.axis('off')\n",
                "\n",
                "    # Grid als Bild speichern\n",
                "    grid_img_path = f\"prediction_grid_{grid_idx+1}.jpg\"\n",
                "    fig.savefig(grid_img_path, bbox_inches='tight', pad_inches=0)\n",
                "    plt.close(fig)\n",
                "\n",
                "    # Bild bei wandb loggen\n",
                "    wandb.log({f\"/custom/grids/prediction_grid_{grid_idx+1}\": wandb.Image(grid_img_path)})\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71a07f9b",
            "metadata": {},
            "source": [
                "## CUSTOM Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5c85f7d",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "Sample larger than population or is negative",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m all_image_paths \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 200 zufällige auswählen\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m selected_images \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_image_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Grid-Parameter\u001b[39;00m\n\u001b[1;32m     34\u001b[0m grid_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/random.py:482\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    480\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    484\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
                        "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import wandb\n",
                "import numpy as np\n",
                "import find_usefull_images_scripts as im_script\n",
                "\n",
                "# # Mapping von Model-Output-Klasse → GT-Klasse\n",
                "label_translation_trained_on_10classes = {\n",
                "    0: 1, 1: 3, 2: 4, 3: 13, 4: 48, 5: 26, 6: 2, 7:42, 8: 9, 9: 5\n",
                "}\n",
                "\n",
                "\n",
                "# label_translation_trained_on_small_set = {\n",
                "#     0: 1, 1: 3, 2: 4, 3: 48, 4: 26, 5: 2, 6: 5\n",
                "# }\n",
                "\n",
                "def compute_classnorm_metrics(gt_dicts, pred_dicts):\n",
                "    \"\"\"\n",
                "    Berechnet class-normalisierte Precision, Recall, F1,\n",
                "    wobei Klassen ohne Vorkommen ignoriert werden.\n",
                "    \"\"\"\n",
                "    all_classes = sorted(set().union(*[d.keys() for d in gt_dicts + pred_dicts]))\n",
                "    \n",
                "    classwise_precisions = []\n",
                "    classwise_recalls = []\n",
                "    classwise_f1s = []\n",
                "    classwise_gt_count = []\n",
                "    classwise_pred_count = []\n",
                "    classwise_fp = []\n",
                "    classwise_fn = []\n",
                "    classwise_tp = []\n",
                "\n",
                "    for cls in all_classes:\n",
                "        tp, fp, fn = 0, 0, 0\n",
                "        gt_count_class = 0\n",
                "        pred_count_class = 0\n",
                "        for gt, pred in zip(gt_dicts, pred_dicts):\n",
                "            gt_count = gt.get(cls, 0)\n",
                "            pred_count = pred.get(cls, 0)\n",
                "            gt_count_class += gt_count\n",
                "            pred_count_class += pred_count\n",
                "\n",
                "            tp += min(gt_count, pred_count)\n",
                "            fp += max(0, pred_count - gt_count)\n",
                "            fn += max(0, gt_count - pred_count)\n",
                "\n",
                "\n",
                "        # Skip class if both gt and pred are zero\n",
                "        if cls == 3:\n",
                "            print(\"avocado\", tp, fp, fn)\n",
                "        if (tp + fp + fn) == 0:\n",
                "            continue\n",
                "\n",
                "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
                "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
                "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
                "\n",
                "        classwise_gt_count.append(gt_count_class)\n",
                "        classwise_pred_count.append(pred_count_class)\n",
                "        classwise_fp.append(fp)\n",
                "        classwise_fn.append(fn)\n",
                "        classwise_tp.append(tp)\n",
                "        classwise_precisions.append(precision)\n",
                "        classwise_recalls.append(recall)\n",
                "        classwise_f1s.append(f1)\n",
                "    \n",
                "    mean_precision = np.mean(classwise_precisions) if len(classwise_precisions) > 0 else 0.0\n",
                "    mean_recall = np.mean(classwise_recalls) if len(classwise_recalls) > 0 else 0.0\n",
                "    mean_f1 = np.mean(classwise_f1s) if len(classwise_f1s) > 0 else 0.0\n",
                "\n",
                "    results = {\"class_norm_precision\": mean_precision, \"class_norm_recall\": mean_recall, \"class_norm_f1\": mean_f1, \n",
                "               \"classwise_gt_count\": classwise_gt_count, \"classwise_pred_count\": classwise_pred_count, \"classwise_fp\": classwise_fp, \"classwise_fn\": classwise_fn,\n",
                "               \"classwise_tp\": classwise_tp, \"classwise_precisions\": classwise_precisions, \"classwise_recalls\": classwise_recalls, \"classwise_f1s\" :classwise_f1s }\n",
                "\n",
                "    return results\n",
                "\n",
                "\n",
                "\n",
                "def compute_global_metrics(gt_dicts, pred_dicts):\n",
                "    all_classes = sorted(set().union(*[d.keys() for d in gt_dicts + pred_dicts]))\n",
                "\n",
                "    def dict_to_vec(d, classes):\n",
                "        return np.array([d.get(c, 0) for c in classes], dtype=np.float32)\n",
                "\n",
                "    gt_arr = np.stack([dict_to_vec(d, all_classes) for d in gt_dicts])\n",
                "    pred_arr = np.stack([dict_to_vec(d, all_classes) for d in pred_dicts])\n",
                "    print(gt_arr, pred_arr)\n",
                "\n",
                "    tp = np.minimum(gt_arr, pred_arr).sum()\n",
                "    fp = np.maximum(pred_arr - gt_arr, 0).sum()\n",
                "    fn = np.maximum(gt_arr - pred_arr, 0).sum()\n",
                "\n",
                "\n",
                "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
                "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
                "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
                "\n",
                "    return precision, recall, f1\n",
                "\n",
                "\n",
                "def translate_prediction_counts(pred_classes, translation_dict):\n",
                "    \"\"\"\n",
                "    Zählt vorhergesagte Klassen und übersetzt sie in Zielklassen.\n",
                "    Gibt dict {gt_class_id: count} zurück.\n",
                "    \"\"\"\n",
                "    pred_counts = {}\n",
                "    for c in pred_classes:\n",
                "        mapped = translation_dict[c]\n",
                "        if mapped is not None:\n",
                "            # get is a cool trick standard value of 0 allows to access even though its not initialised\n",
                "            pred_counts[mapped] = pred_counts.get(mapped, 0) + 1\n",
                "    return pred_counts\n",
                "\n",
                "# === Main ===\n",
                "\n",
                "image_paths, label_lines = im_script.get_custom_10class_class_dataset()\n",
                "batch_size = 20\n",
                "\n",
                "all_gt_counts = []\n",
                "all_pred_counts = []\n",
                "\n",
                "for i in range(0, len(image_paths), batch_size):\n",
                "    batch_paths = image_paths[i:i + batch_size]\n",
                "    batch_labels = label_lines[i:i + batch_size]  # dicts: class_id -> count (GT-Klassen)\n",
                "\n",
                "    # GT-Labels direkt übernehmen\n",
                "    all_gt_counts.extend(batch_labels)\n",
                "\n",
                "    # Model Predictions holen\n",
                "    preds_raw = model.predict(batch_paths, imgsz=IMG_SIZE, stream=False)\n",
                "\n",
                "    for i, pred in enumerate(preds_raw):\n",
                "        pred_classes = pred.boxes.cls.cpu().tolist()\n",
                "        translated_pred = translate_prediction_counts(pred_classes, label_translation_trained_on_10classes)\n",
                "        all_pred_counts.append(translated_pred)\n",
                "\n",
                "\n",
                "precision, recall, f1 = compute_global_metrics(all_gt_counts, all_pred_counts)\n",
                "\n",
                "\n",
                "# Zusätzlich: class-normalisierte Metriken berechnen\n",
                "results = compute_classnorm_metrics(all_gt_counts, all_pred_counts)\n",
                "\n",
                "\n",
                "\n",
                "print(precision, recall, f1, results[\"class_norm_precision\"], results[\"class_norm_recall\"], results[\"class_norm_f1\"])\n",
                "wandb.log({\n",
                "    \"custom/test/precision_counts\": float(precision),\n",
                "    \"custom/test/recall_counts\": float(recall),\n",
                "    \"custom/test/f1_score_counts\": float(f1),\n",
                "    \"custom/test/precision_classnorm_CARE\": float(results[\"class_norm_precision\"]),\n",
                "    \"custom/test/recall_classnorm_CARE\": float( results[\"class_norm_recall\"]),\n",
                "    \"custom/test/f1_classnorm_CARE\": float( results[\"class_norm_f1\"])\n",
                "}, step=wandb.run.step)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "a300df26",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.19.4"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/data22/stu236894/GitRepos/TinyML-MT/code_training/classification-code/wandb/run-20250616_224553-havg57rg</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Resuming run <strong><a href='https://wandb.ai/maats/Yolo-Training/runs/havg57rg' target=\"_blank\">fixed_metrics_compare_first_artificial_dataset_again16Jun-16:13:20</a></strong> to <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/maats/Yolo-Training/runs/havg57rg' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/havg57rg</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/maats/Yolo-Training/runs/havg57rg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x7f0e2ba71ed0>"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import wandb\n",
                "\n",
                "\n",
                "# Deine Run-ID, z. B. \"ls3jwotb\" aus der URL oder dem lokalen Log\n",
                "# Deine Run-ID, z. B. \"ls3jwotb\" aus der URL oder dem lokalen Log\n",
                "run_id = \"havg57rg\"\n",
                "\n",
                "# Reaktiviere den Run\n",
                "wandb.init(\n",
                "    project=\"Yolo-Training\",\n",
                "    entity=\"maats\",\n",
                "    id=run_id,\n",
                "    resume=\"allow\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f4a249bb",
            "metadata": {},
            "source": [
                "## CUSTOM Heatmap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8ab8a66",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "\n",
                "# === Labels vorbereiten ===\n",
                "model_names = model.names  # z. B. {0: \"apple\", 1: \"banana\", ...}\n",
                "translation = label_translation_trained_on_10classes\n",
                "\n",
                "translated_class_labels = {\n",
                "    gt_id: model_names[pred_id]\n",
                "    for pred_id, gt_id in translation.items()\n",
                "}\n",
                "\n",
                "# === Werte aus results extrahieren ===\n",
                "class_ids = sorted(translated_class_labels.keys())  # Nur GT-Klassen, die in der Übersetzung vorkommen\n",
                "prec_list = [results[\"classwise_precisions\"][class_ids.index(c)] for c in class_ids]\n",
                "recall_list = [results[\"classwise_recalls\"][class_ids.index(c)] for c in class_ids]\n",
                "f1_list = [results[\"classwise_f1s\"][class_ids.index(c)] for c in class_ids]\n",
                "\n",
                "# === Heatmap zeichnen ===\n",
                "metric_matrix = np.array([prec_list, recall_list, f1_list])\n",
                "metric_labels = [\"Precision\", \"Recall\", \"F1\"]\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(max(8, len(class_ids)), 4))\n",
                "sns.heatmap(\n",
                "    metric_matrix,\n",
                "    annot=True,\n",
                "    fmt=\".2f\",\n",
                "    cmap=\"YlGnBu\",\n",
                "    vmin=0.0,\n",
                "    vmax=1.0,\n",
                "    xticklabels=[translated_class_labels.get(c, str(c)) for c in class_ids],\n",
                "    yticklabels=metric_labels,\n",
                "    ax=ax\n",
                ")\n",
                "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
                "plt.title(\"Per-Class Precision / Recall / F1\")\n",
                "plt.xlabel(\"Klasse\")\n",
                "plt.ylabel(\"Metrik\")\n",
                "plt.tight_layout()\n",
                "\n",
                "wandb.log({\"custom/per_class_metrics_heatmap\": wandb.Image(fig)})\n",
                "plt.close(fig)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a097571b",
            "metadata": {},
            "source": [
                "## Finish WandB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "f20ac5c5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">mvtec19Jun-19:34:00</strong> at: <a href='https://wandb.ai/maats/Yolo-Training/runs/jom3jhke' target=\"_blank\">https://wandb.ai/maats/Yolo-Training/runs/jom3jhke</a><br> View project at: <a href='https://wandb.ai/maats/Yolo-Training' target=\"_blank\">https://wandb.ai/maats/Yolo-Training</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20250619_193401-jom3jhke/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "wandb.finish()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "basket",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
